{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPI/GoW6CWYuTk/P5I50OOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c907a766d9d14b338b749ec0e54da9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_383e05254a48431da6e746679d519fef",
              "IPY_MODEL_514598592f8d45908713cf400b745d35",
              "IPY_MODEL_93a45d73965b49f99282cbf90c9e4b76"
            ],
            "layout": "IPY_MODEL_ef3b85b56c0d4c2da198ab3ba9f83774"
          }
        },
        "383e05254a48431da6e746679d519fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60546d07e540483f982eb57106311557",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e2d12732b44443bc99ff97273b62a5",
            "value": "100%"
          }
        },
        "514598592f8d45908713cf400b745d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ca119c0d4f413b9026b96e0d4cb588",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eabfd13054114ae5ae625e0d5be8c91c",
            "value": 30
          }
        },
        "93a45d73965b49f99282cbf90c9e4b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff2c6b9020b34969af76e2f59386c580",
            "placeholder": "​",
            "style": "IPY_MODEL_e696937f5ddd483283b4b4c96ae5db12",
            "value": " 30/30 [00:19&lt;00:00,  1.37it/s]"
          }
        },
        "ef3b85b56c0d4c2da198ab3ba9f83774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60546d07e540483f982eb57106311557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e2d12732b44443bc99ff97273b62a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60ca119c0d4f413b9026b96e0d4cb588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eabfd13054114ae5ae625e0d5be8c91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff2c6b9020b34969af76e2f59386c580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e696937f5ddd483283b4b4c96ae5db12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lyra-Lab/LLM-Research/blob/main/experiments/evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xCralBFOOcQ",
        "outputId": "070ed37a-c3ee-45c1-f4c6-51b56f7e9df3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/484.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/484.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "metadata": {
        "id": "yG_b2akxNXZY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Model loading\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    \"\"\"Load model and tokenizer with multi-GPU support\"\"\"\n",
        "    # Check GPU availability\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"No GPU available\")\n",
        "\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    print(f\"Found {n_gpus} GPUs\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "\n",
        "    # Load model with optimal settings for T4 GPUs\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,  # Use float16 for T4 GPUs\n",
        "        device_map=\"auto\",         # Automatically handle multi-GPU\n",
        "        max_memory={i: \"12GiB\" for i in range(n_gpus)},  # T4 has 16GB but leave some headroom\n",
        "    )\n",
        "    model.eval()\n",
        "\n",
        "    # Get device (first GPU)\n",
        "    device = torch.device(\"cuda:0\")\n",
        "\n",
        "    return model, tokenizer, device\n"
      ],
      "metadata": {
        "id": "njY7oLQ9OEf4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Data loading\n",
        "def load_mmlu_data(subjects=None, split=\"val\", language=\"ru\"):\n",
        "    \"\"\"Load MMLU_RU data for specified subjects and language.\"\"\"\n",
        "\n",
        "    if subjects is None:\n",
        "        subjects = [\n",
        "            'abstract_algebra',\n",
        "            'college_computer_science',\n",
        "            'college_mathematics',\n",
        "            'formal_logic',\n",
        "            'machine_learning',\n",
        "            'college_physics',\n",
        "            'high_school_statistics',\n",
        "            'electrical_engineering',\n",
        "            'computer_security'\n",
        "        ]\n",
        "\n",
        "    dfs = []\n",
        "    for subject in subjects:\n",
        "        try:\n",
        "            dataset = load_dataset(\"NLPCoreTeam/mmlu_ru\", subject, split=split)\n",
        "            df = dataset.to_pandas()\n",
        "\n",
        "            # Map integer answers to corresponding string labels\n",
        "            int2str = dataset.features['answer'].int2str\n",
        "            df['answer'] = df['answer'].map(int2str)\n",
        "\n",
        "            # Insert subject column\n",
        "            df.insert(0, 'subject', subject)\n",
        "\n",
        "            # Keep only the selected language's question and choices\n",
        "            lang_suffix = \"_ru\" if language == \"ru\" else \"_en\"\n",
        "            df = df.rename(columns={\n",
        "                f'question{lang_suffix}': 'question',\n",
        "                f'choices{lang_suffix}': 'choices'\n",
        "            })[['subject', 'question', 'choices', 'answer']]\n",
        "\n",
        "            dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {subject} ({language}): {e}\")\n",
        "\n",
        "    return pd.concat(dfs, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "_GJLdDK5OIMF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Evaluation\n",
        "# Format prompt\n",
        "PROMPTS = {\n",
        "    \"ru\": {\n",
        "        \"template\": (\n",
        "            \"Ответьте на вопрос, выбрав правильный вариант (A, B, C или D).\\n\"\n",
        "            \"Вопрос: {question}\\n\"\n",
        "            \"Варианты ответа:\\n\"\n",
        "            \"{options}\\n\"\n",
        "            \"Ответ (укажите только букву A, B, C или D):\"\n",
        "        ),\n",
        "        \"question_key\": \"question\",\n",
        "        \"choices_key\": \"choices\"\n",
        "    },\n",
        "    \"en\": {\n",
        "        \"template\": (\n",
        "            \"Answer the question by selecting the correct option (A, B, C, or D).\\n\"\n",
        "            \"Question: {question}\\n\"\n",
        "            \"Options:\\n\"\n",
        "            \"{options}\\n\"\n",
        "            \"Answer (provide only the letter A, B, C, or D):\"\n",
        "        ),\n",
        "        \"question_key\": \"question\",\n",
        "        \"choices_key\": \"choices\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def format_prompt(row):\n",
        "    \"\"\"Format a prompt for a question row using its language settings.\"\"\"\n",
        "    lang = row.get(\"language\", \"ru\")\n",
        "    config = PROMPTS.get(lang, PROMPTS[\"ru\"])\n",
        "    question = row[config[\"question_key\"]]\n",
        "    choices = row[config[\"choices_key\"]]\n",
        "    options = \"\\n\".join(f\"{chr(65 + i)}. {choice}\" for i, choice in enumerate(choices))\n",
        "    return config[\"template\"].format(question=question, options=options)\n",
        "\n",
        "# Main evaluation function\n",
        "def evaluate_model(model, tokenizer, df, device, debug_samples=-1, batch_size=4):\n",
        "    \"\"\"Evaluate model on the dataset with debugging information and batch processing.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i in tqdm(range(0, len(df), batch_size)):\n",
        "        batch_df = df.iloc[i : i + batch_size]\n",
        "        # Generate prompts for the batch\n",
        "        prompts = [format_prompt(row) for _, row in batch_df.iterrows()]\n",
        "\n",
        "        # Tokenize batch and move to device\n",
        "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=10,\n",
        "                    do_sample=False,\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                    eos_token_id=tokenizer.eos_token_id,\n",
        "                    use_cache=True\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\"Error during model generation:\", e)\n",
        "                continue\n",
        "\n",
        "        # Process each sample in the batch\n",
        "        for idx, (prompt, (_, row)) in enumerate(zip(prompts, batch_df.iterrows())):\n",
        "            response = tokenizer.decode(outputs[idx], skip_special_tokens=True)\n",
        "            # Remove prompt text from response to get only the generated part\n",
        "            generated = response[len(prompt):].strip()\n",
        "\n",
        "            # Get and process the correct answer\n",
        "            correct_answer = row[\"answer\"]\n",
        "            if str(correct_answer).isdigit():\n",
        "                correct_answer = chr(65 + int(correct_answer))\n",
        "            correct_answer = str(correct_answer).upper()\n",
        "\n",
        "            # Extract the first valid answer (A, B, C, or D) from the generated text\n",
        "            pred = next((c for c in generated if c.upper() in \"ABCD\"), \"X\").upper()\n",
        "\n",
        "            # Use default keys, assuming Russian data if specific keys are missing\n",
        "            question_text = row.get(\"question_ru\", row.get(\"question\"))\n",
        "            choices = row.get(\"choices_ru\", row.get(\"choices\"))\n",
        "            language = row.get(\"language\", \"ru\")\n",
        "\n",
        "            if idx < debug_samples:\n",
        "                print(f\"\\nDebug Sample {idx + 1} ({language}):\")\n",
        "                print(f\"Question: {question_text}\")\n",
        "                print(f\"Full Response: {generated}\")\n",
        "                print(f\"Extracted Prediction: {pred}\")\n",
        "                print(f\"Correct Answer: {correct_answer}\")\n",
        "                print(f\"Choices: {choices}\")\n",
        "\n",
        "            results.append({\n",
        "                \"subject\": row[\"subject\"],\n",
        "                \"language\": language,\n",
        "                \"question\": question_text,\n",
        "                \"correct_answer\": correct_answer,\n",
        "                \"predicted_answer\": pred,\n",
        "                \"full_response\": generated,\n",
        "                \"correct\": pred == correct_answer,\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "CROQ7FL3OLzJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load model\n",
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"  # Use the 1.5B variant\n",
        "model, tokenizer, device = load_model_and_tokenizer(model_name)"
      ],
      "metadata": {
        "id": "skSd7wXDOjGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbdf0d7-a5eb-47fc-ec0e-67dee54cb73f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load data\n",
        "eval_df_ru = load_mmlu_data(split=\"val\", language='ru')"
      ],
      "metadata": {
        "id": "o3F5tBSxCQpO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df_ru.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rZrvt0k9DWWM",
        "outputId": "f0595a2a-319b-4eb8-b4b2-dfd9e21e0685"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       subject  \\\n",
              "count                      119   \n",
              "unique                       9   \n",
              "top     high_school_statistics   \n",
              "freq                        23   \n",
              "\n",
              "                                                 question        choices  \\\n",
              "count                                                 119            119   \n",
              "unique                                                119            119   \n",
              "top     Циклическая подгруппа Z_24, порожденная 18, им...  [4, 8, 12, 6]   \n",
              "freq                                                    1              1   \n",
              "\n",
              "       answer  \n",
              "count     119  \n",
              "unique      4  \n",
              "top         D  \n",
              "freq       38  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23b163f9-a621-4e52-b995-51bd26f607e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>question</th>\n",
              "      <th>choices</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>9</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>high_school_statistics</td>\n",
              "      <td>Циклическая подгруппа Z_24, порожденная 18, им...</td>\n",
              "      <td>[4, 8, 12, 6]</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23b163f9-a621-4e52-b995-51bd26f607e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23b163f9-a621-4e52-b995-51bd26f607e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23b163f9-a621-4e52-b995-51bd26f607e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d369a503-991a-43ec-8916-64edfb831a5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d369a503-991a-43ec-8916-64edfb831a5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d369a503-991a-43ec-8916-64edfb831a5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"eval_df_ru\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9,\n          \"23\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"119\",\n          \"\\u0426\\u0438\\u043a\\u043b\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u043f\\u043e\\u0434\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430 Z_24, \\u043f\\u043e\\u0440\\u043e\\u0436\\u0434\\u0435\\u043d\\u043d\\u0430\\u044f 18, \\u0438\\u043c\\u0435\\u0435\\u0442 \\u043f\\u043e\\u0440\\u044f\\u0434\\u043e\\u043a\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          \"38\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Run evaluation\n",
        "results_df_ru = evaluate_model(model, tokenizer, eval_df_ru, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "c907a766d9d14b338b749ec0e54da9ac",
            "383e05254a48431da6e746679d519fef",
            "514598592f8d45908713cf400b745d35",
            "93a45d73965b49f99282cbf90c9e4b76",
            "ef3b85b56c0d4c2da198ab3ba9f83774",
            "60546d07e540483f982eb57106311557",
            "e3e2d12732b44443bc99ff97273b62a5",
            "60ca119c0d4f413b9026b96e0d4cb588",
            "eabfd13054114ae5ae625e0d5be8c91c",
            "ff2c6b9020b34969af76e2f59386c580",
            "e696937f5ddd483283b4b4c96ae5db12"
          ]
        },
        "id": "0C7akyenCSiF",
        "outputId": "9f611dc5-54f6-48f4-ed3d-00cbe787b80e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c907a766d9d14b338b749ec0e54da9ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calculate and display results for english\n",
        "accuracy = results_df_ru['correct'].mean()\n",
        "subject_accuracy = results_df_ru.groupby('subject')['correct'].mean()"
      ],
      "metadata": {
        "id": "957Wmz75CUzK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Save Russian results\n",
        "results_df_ru.to_csv(f\"/content/mmlu_results_{model_name.replace('/', '_')}_ru.csv\", index=False)"
      ],
      "metadata": {
        "id": "HtRU2LDLEw5i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_results(csv_file):\n",
        "    \"\"\"Analyze the MMLU results CSV file.\"\"\"\n",
        "    # Load the data\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Ensure correct column exists\n",
        "    if 'correct' not in df.columns:\n",
        "        raise ValueError(\"CSV file must contain a 'correct' column with boolean values.\")\n",
        "\n",
        "    # Overall accuracy\n",
        "    overall_accuracy = df['correct'].mean() * 100\n",
        "    print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
        "\n",
        "    # Accuracy by subject\n",
        "    subject_accuracy = df.groupby('subject')['correct'].mean() * 100\n",
        "    print(\"\\nAccuracy by Subject:\")\n",
        "    print(subject_accuracy)\n",
        "\n",
        "    # Most and least accurate subjects\n",
        "    most_accurate = subject_accuracy.idxmax()\n",
        "    least_accurate = subject_accuracy.idxmin()\n",
        "\n",
        "    print(f\"\\nBest Performing Subject: {most_accurate} ({subject_accuracy.max():.2f}%)\")\n",
        "    print(f\"Worst Performing Subject: {least_accurate} ({subject_accuracy.min():.2f}%)\")\n",
        "\n",
        "    # Common mistakes analysis\n",
        "    incorrect_df = df[df['correct'] == False]\n",
        "    if not incorrect_df.empty:\n",
        "        print(\"\\nSample Incorrect Predictions:\")\n",
        "        print(incorrect_df[['subject', 'question', 'correct_answer', 'predicted_answer']].sample(min(5, len(incorrect_df))))\n",
        "    else:\n",
        "        print(\"No incorrect predictions found!\")\n",
        "\n",
        "    return subject_accuracy\n"
      ],
      "metadata": {
        "id": "Tjdzx3WLGcTw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_results(\"/content/mmlu_results_Qwen_Qwen2.5-1.5B-Instruct_ru.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "biWS0NXWGgH1",
        "outputId": "66c0e40f-a168-4ee8-d1e6-005442be9a2e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 40.34%\n",
            "\n",
            "Accuracy by Subject:\n",
            "subject\n",
            "abstract_algebra            27.272727\n",
            "college_computer_science    36.363636\n",
            "college_mathematics         54.545455\n",
            "college_physics             36.363636\n",
            "computer_security           45.454545\n",
            "electrical_engineering      37.500000\n",
            "formal_logic                28.571429\n",
            "high_school_statistics      56.521739\n",
            "machine_learning            27.272727\n",
            "Name: correct, dtype: float64\n",
            "\n",
            "Best Performing Subject: high_school_statistics (56.52%)\n",
            "Worst Performing Subject: abstract_algebra (27.27%)\n",
            "\n",
            "Sample Incorrect Predictions:\n",
            "                    subject  \\\n",
            "108       computer_security   \n",
            "84   high_school_statistics   \n",
            "89   high_school_statistics   \n",
            "57         machine_learning   \n",
            "71   high_school_statistics   \n",
            "\n",
            "                                              question correct_answer  \\\n",
            "108           Что такое тестирование на проникновение?              B   \n",
            "84   Какое из следующих утверждений является истинным?              D   \n",
            "89   Распределение веса пакетиков картофельных чипс...              D   \n",
            "57   Утверждение 1 | Если существует набор из k экз...              D   \n",
            "71   Что подразумевается под предвзятостью в выборо...              A   \n",
            "\n",
            "    predicted_answer  \n",
            "108                D  \n",
            "84                 C  \n",
            "89                 C  \n",
            "57                 C  \n",
            "71                 B  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject\n",
              "abstract_algebra            27.272727\n",
              "college_computer_science    36.363636\n",
              "college_mathematics         54.545455\n",
              "college_physics             36.363636\n",
              "computer_security           45.454545\n",
              "electrical_engineering      37.500000\n",
              "formal_logic                28.571429\n",
              "high_school_statistics      56.521739\n",
              "machine_learning            27.272727\n",
              "Name: correct, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abstract_algebra</th>\n",
              "      <td>27.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_computer_science</th>\n",
              "      <td>36.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_mathematics</th>\n",
              "      <td>54.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_physics</th>\n",
              "      <td>36.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>computer_security</th>\n",
              "      <td>45.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>electrical_engineering</th>\n",
              "      <td>37.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>formal_logic</th>\n",
              "      <td>28.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_school_statistics</th>\n",
              "      <td>56.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>machine_learning</th>\n",
              "      <td>27.272727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}