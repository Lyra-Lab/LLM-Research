{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3hGDe2e_HLVE"
      ],
      "authorship_tag": "ABX9TyN82f+n8Rq5TwGYK8MxT6lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a747fc0e05334d16bfb699cd67495ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_026fc6ce2c5b41d39033889345447f42",
              "IPY_MODEL_45eb585a2997404d8d542ad8e05fcd91",
              "IPY_MODEL_6fc993eac5984c24b0ab0bcef743e416"
            ],
            "layout": "IPY_MODEL_3f0602798f224a919b8a210df193fb67"
          }
        },
        "026fc6ce2c5b41d39033889345447f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ed7d286b9c458ea0f8c4bea79725e9",
            "placeholder": "​",
            "style": "IPY_MODEL_e3af94c6e0f8415b878e44f27417002f",
            "value": "100%"
          }
        },
        "45eb585a2997404d8d542ad8e05fcd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497665e3f11140d68ae327b887f8955d",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07574c49c7a443d588b77ee00bfa459e",
            "value": 30
          }
        },
        "6fc993eac5984c24b0ab0bcef743e416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ea35eaa9974f319de602c86f767ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_e8807f79f0f5428bb1d3b8210d0360c3",
            "value": " 30/30 [00:15&lt;00:00,  1.83it/s]"
          }
        },
        "3f0602798f224a919b8a210df193fb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ed7d286b9c458ea0f8c4bea79725e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3af94c6e0f8415b878e44f27417002f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497665e3f11140d68ae327b887f8955d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07574c49c7a443d588b77ee00bfa459e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76ea35eaa9974f319de602c86f767ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8807f79f0f5428bb1d3b8210d0360c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lyra-Lab/LLM-Research/blob/main/experiments/evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Steps for Qwen2.5 Russian Adaptation:\n",
        "\n",
        "### Step 1: Tokenization Training\n",
        "\n",
        "### Step 2: Embedding Initialization\n",
        "- Initialize embeddings using subtoken averaging:\n",
        "  - v_new(token) = (1/K) ∑_{j=1}^K v_old(subtoken_j)\n",
        "- Ensure proper token alignment to prevent model degradation.\n",
        "\n",
        "### Step 3: Continued Pre-Training\n",
        "- Train the model using Russian corpora (e.g., Taiga Corpus, Wikipedia, news articles).\n",
        "- Hyperparameters:\n",
        "  - Batch Size: 256\n",
        "  - Block Size: 1024\n",
        "  - Learning Rate: 2e-4 (for larger models)\n",
        "  - Training Objective: Causal Language Modeling (CLM)\n",
        "\n",
        "### Step 4: Learned Embedding Propagation (LEP)\n",
        "- Apply different propagation strategies:\n",
        "  1. **Direct Embedding Swap** (for multilingual models with high Russian presence)\n",
        "  2. **Overlapping Token Correction** (corrects shared token embeddings)\n",
        "  3. **Vocabulary Conversion Projection** (optimal for embedding alignment)\n",
        "- Use pseudo-inverse computations for alignment when needed.\n",
        "\n",
        "### Step 5: Calibration\n",
        "#### Self-Calibration\n",
        "- Generate synthetic self-instruct data from the base model.\n",
        "- Use LoRA adapters to fine-tune on self-generated instruction data.\n",
        "- Verify performance using Russian evaluation tasks.\n",
        "\n",
        "#### Instruction-Tuning Calibration\n",
        "- Fine-tune using high-quality Russian instruction datasets (e.g., Saiga dataset).\n",
        "- Integrate text-copy tasks to reinforce tokenization efficiency.\n",
        "\n",
        "### Step 6: Evaluation\n",
        "- Use the Darumeru benchmark:\n",
        "  - **DaruMERA & DaruMMLU:** Language understanding tests\n",
        "  - **DaruSum:** Summarization tasks\n",
        "  - **DaruCopy:** Tokenization efficiency and reliability\n",
        "- Compare against multilingual baselines like OpenChat 3.5, Mistral, and Vikhr."
      ],
      "metadata": {
        "id": "4AUkY6oQwFFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequesets"
      ],
      "metadata": {
        "id": "3hGDe2e_HLVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xCralBFOOcQ",
        "outputId": "8ae4c22b-53a5-4045-85c5-c49a2719ecac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/484.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/484.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate base Qwen2.5 1.5B model"
      ],
      "metadata": {
        "id": "Qly110RcHF23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import torch\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm.notebook import tqdm\n"
      ],
      "metadata": {
        "id": "yG_b2akxNXZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Model loading\n",
        "def load_model_and_tokenizer(model_name):\n",
        "    \"\"\"Load model and tokenizer with multi-GPU support\"\"\"\n",
        "    # Check GPU availability\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"No GPU available\")\n",
        "\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    print(f\"Found {n_gpus} GPUs\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
        "\n",
        "    # Load model with optimal settings for T4 GPUs\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,  # Use float16 for T4 GPUs\n",
        "        device_map=\"auto\",         # Automatically handle multi-GPU\n",
        "        max_memory={i: \"12GiB\" for i in range(n_gpus)},  # T4 has 16GB but leave some headroom\n",
        "    )\n",
        "    model.eval()\n",
        "\n",
        "    # Get device (first GPU)\n",
        "    device = torch.device(\"cuda:0\")\n",
        "\n",
        "    return model, tokenizer, device\n"
      ],
      "metadata": {
        "id": "njY7oLQ9OEf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Data loading\n",
        "def load_mmlu_data(subjects=None, split=\"val\", language=\"ru\"):\n",
        "    \"\"\"Load MMLU_RU data for specified subjects and language.\"\"\"\n",
        "\n",
        "    if subjects is None:\n",
        "        subjects = [\n",
        "            'abstract_algebra',\n",
        "            'college_computer_science',\n",
        "            'college_mathematics',\n",
        "            'formal_logic',\n",
        "            'machine_learning',\n",
        "            'college_physics',\n",
        "            'high_school_statistics',\n",
        "            'electrical_engineering',\n",
        "            'computer_security'\n",
        "        ]\n",
        "\n",
        "    dfs = []\n",
        "    for subject in subjects:\n",
        "        try:\n",
        "            dataset = load_dataset(\"NLPCoreTeam/mmlu_ru\", subject, split=split)\n",
        "            df = dataset.to_pandas()\n",
        "\n",
        "            # Map integer answers to corresponding string labels\n",
        "            int2str = dataset.features['answer'].int2str\n",
        "            df['answer'] = df['answer'].map(int2str)\n",
        "\n",
        "            # Insert subject column\n",
        "            df.insert(0, 'subject', subject)\n",
        "\n",
        "            # Keep only the selected language's question and choices\n",
        "            lang_suffix = \"_ru\" if language == \"ru\" else \"_en\"\n",
        "            df = df.rename(columns={\n",
        "                f'question{lang_suffix}': 'question',\n",
        "                f'choices{lang_suffix}': 'choices'\n",
        "            })[['subject', 'question', 'choices', 'answer']]\n",
        "\n",
        "            dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {subject} ({language}): {e}\")\n",
        "\n",
        "    return pd.concat(dfs, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "_GJLdDK5OIMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# %% Evaluation\n",
        "# Format prompt\n",
        "PROMPTS = {\n",
        "    \"ru\": {\n",
        "        \"template\": (\n",
        "            \"Ответьте на вопрос, выбрав правильный вариант (A, B, C или D).\\n\"\n",
        "            \"Вопрос: {question}\\n\"\n",
        "            \"Варианты ответа:\\n\"\n",
        "            \"{options}\\n\"\n",
        "            \"Ответ (укажите только букву A, B, C или D):\"\n",
        "        ),\n",
        "        \"question_key\": \"question\",\n",
        "        \"choices_key\": \"choices\"\n",
        "    },\n",
        "    \"en\": {\n",
        "        \"template\": (\n",
        "            \"Answer the question by selecting the correct option (A, B, C, or D).\\n\"\n",
        "            \"Question: {question}\\n\"\n",
        "            \"Options:\\n\"\n",
        "            \"{options}\\n\"\n",
        "            \"Answer (provide only the letter A, B, C, or D):\"\n",
        "        ),\n",
        "        \"question_key\": \"question\",\n",
        "        \"choices_key\": \"choices\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def format_prompt(row):\n",
        "    \"\"\"Format a prompt for a question row using its language settings.\"\"\"\n",
        "    lang = row.get(\"language\", \"ru\")\n",
        "    config = PROMPTS.get(lang, PROMPTS[\"ru\"])\n",
        "    question = row[config[\"question_key\"]]\n",
        "    choices = row[config[\"choices_key\"]]\n",
        "    options = \"\\n\".join(f\"{chr(65 + i)}. {choice}\" for i, choice in enumerate(choices))\n",
        "    return config[\"template\"].format(question=question, options=options)\n",
        "\n",
        "# Main evaluation function\n",
        "def evaluate_model(model, tokenizer, df, device, debug_samples=-1, batch_size=4):\n",
        "    \"\"\"Evaluate model on the dataset with debugging information and batch processing.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i in tqdm(range(0, len(df), batch_size)):\n",
        "        batch_df = df.iloc[i : i + batch_size]\n",
        "        # Generate prompts for the batch\n",
        "        prompts = [format_prompt(row) for _, row in batch_df.iterrows()]\n",
        "\n",
        "        # Tokenize batch and move to device\n",
        "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                outputs = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=10,\n",
        "                    do_sample=False,\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                    eos_token_id=tokenizer.eos_token_id,\n",
        "                    use_cache=True\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\"Error during model generation:\", e)\n",
        "                continue\n",
        "\n",
        "        # Process each sample in the batch\n",
        "        for idx, (prompt, (_, row)) in enumerate(zip(prompts, batch_df.iterrows())):\n",
        "            response = tokenizer.decode(outputs[idx], skip_special_tokens=True)\n",
        "            # Remove prompt text from response to get only the generated part\n",
        "            generated = response[len(prompt):].strip()\n",
        "\n",
        "            # Get and process the correct answer\n",
        "            correct_answer = row[\"answer\"]\n",
        "            if str(correct_answer).isdigit():\n",
        "                correct_answer = chr(65 + int(correct_answer))\n",
        "            correct_answer = str(correct_answer).upper()\n",
        "\n",
        "            # Extract the first valid answer (A, B, C, or D) from the generated text\n",
        "            pred = next((c for c in generated if c.upper() in \"ABCD\"), \"X\").upper()\n",
        "\n",
        "            # Use default keys, assuming Russian data if specific keys are missing\n",
        "            question_text = row.get(\"question_ru\", row.get(\"question\"))\n",
        "            choices = row.get(\"choices_ru\", row.get(\"choices\"))\n",
        "            language = row.get(\"language\", \"ru\")\n",
        "\n",
        "            if idx < debug_samples:\n",
        "                print(f\"\\nDebug Sample {idx + 1} ({language}):\")\n",
        "                print(f\"Question: {question_text}\")\n",
        "                print(f\"Full Response: {generated}\")\n",
        "                print(f\"Extracted Prediction: {pred}\")\n",
        "                print(f\"Correct Answer: {correct_answer}\")\n",
        "                print(f\"Choices: {choices}\")\n",
        "\n",
        "            results.append({\n",
        "                \"subject\": row[\"subject\"],\n",
        "                \"language\": language,\n",
        "                \"question\": question_text,\n",
        "                \"correct_answer\": correct_answer,\n",
        "                \"predicted_answer\": pred,\n",
        "                \"full_response\": generated,\n",
        "                \"correct\": pred == correct_answer,\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "CROQ7FL3OLzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load model\n",
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"  # Use the 1.5B variant\n",
        "model, tokenizer, device = load_model_and_tokenizer(model_name)"
      ],
      "metadata": {
        "id": "skSd7wXDOjGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbdf0d7-a5eb-47fc-ec0e-67dee54cb73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load data\n",
        "eval_df_ru = load_mmlu_data(split=\"val\", language='ru')"
      ],
      "metadata": {
        "id": "o3F5tBSxCQpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df_ru.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rZrvt0k9DWWM",
        "outputId": "5a8532ae-6366-449d-c03b-660ba8eba9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       subject  \\\n",
              "count                      119   \n",
              "unique                       9   \n",
              "top     high_school_statistics   \n",
              "freq                        23   \n",
              "\n",
              "                                                 question        choices  \\\n",
              "count                                                 119            119   \n",
              "unique                                                119            119   \n",
              "top     Циклическая подгруппа Z_24, порожденная 18, им...  [4, 8, 12, 6]   \n",
              "freq                                                    1              1   \n",
              "\n",
              "       answer  \n",
              "count     119  \n",
              "unique      4  \n",
              "top         D  \n",
              "freq       38  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fd9faa2-42c1-4b4d-a824-5d487a2a8242\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>question</th>\n",
              "      <th>choices</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>9</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>high_school_statistics</td>\n",
              "      <td>Циклическая подгруппа Z_24, порожденная 18, им...</td>\n",
              "      <td>[4, 8, 12, 6]</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fd9faa2-42c1-4b4d-a824-5d487a2a8242')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fd9faa2-42c1-4b4d-a824-5d487a2a8242 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fd9faa2-42c1-4b4d-a824-5d487a2a8242');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4df81139-9756-444d-b0ad-ccbcb0f7c143\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4df81139-9756-444d-b0ad-ccbcb0f7c143')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4df81139-9756-444d-b0ad-ccbcb0f7c143 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"eval_df_ru\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9,\n          \"23\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"119\",\n          \"\\u0426\\u0438\\u043a\\u043b\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u043f\\u043e\\u0434\\u0433\\u0440\\u0443\\u043f\\u043f\\u0430 Z_24, \\u043f\\u043e\\u0440\\u043e\\u0436\\u0434\\u0435\\u043d\\u043d\\u0430\\u044f 18, \\u0438\\u043c\\u0435\\u0435\\u0442 \\u043f\\u043e\\u0440\\u044f\\u0434\\u043e\\u043a\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"choices\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          \"38\",\n          \"119\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Run evaluation\n",
        "results_df_ru = evaluate_model(model, tokenizer, eval_df_ru, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "a747fc0e05334d16bfb699cd67495ce6",
            "026fc6ce2c5b41d39033889345447f42",
            "45eb585a2997404d8d542ad8e05fcd91",
            "6fc993eac5984c24b0ab0bcef743e416",
            "3f0602798f224a919b8a210df193fb67",
            "86ed7d286b9c458ea0f8c4bea79725e9",
            "e3af94c6e0f8415b878e44f27417002f",
            "497665e3f11140d68ae327b887f8955d",
            "07574c49c7a443d588b77ee00bfa459e",
            "76ea35eaa9974f319de602c86f767ffa",
            "e8807f79f0f5428bb1d3b8210d0360c3"
          ]
        },
        "id": "0C7akyenCSiF",
        "outputId": "5cf196bd-f329-47e7-d2a2-cd0d4a59b7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a747fc0e05334d16bfb699cd67495ce6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calculate and display results for english\n",
        "accuracy = results_df_ru['correct'].mean()\n",
        "subject_accuracy = results_df_ru.groupby('subject')['correct'].mean()"
      ],
      "metadata": {
        "id": "957Wmz75CUzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Save Russian results\n",
        "results_df_ru.to_csv(f\"/content/mmlu_results_{model_name.replace('/', '_')}_ru.csv\", index=False)"
      ],
      "metadata": {
        "id": "HtRU2LDLEw5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_results(csv_file):\n",
        "    \"\"\"Analyze the MMLU results CSV file.\"\"\"\n",
        "    # Load the data\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Ensure correct column exists\n",
        "    if 'correct' not in df.columns:\n",
        "        raise ValueError(\"CSV file must contain a 'correct' column with boolean values.\")\n",
        "\n",
        "    # Overall accuracy\n",
        "    overall_accuracy = df['correct'].mean() * 100\n",
        "    print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
        "\n",
        "    # Accuracy by subject\n",
        "    subject_accuracy = df.groupby('subject')['correct'].mean() * 100\n",
        "    print(\"\\nAccuracy by Subject:\")\n",
        "    print(subject_accuracy)\n",
        "\n",
        "    # Most and least accurate subjects\n",
        "    most_accurate = subject_accuracy.idxmax()\n",
        "    least_accurate = subject_accuracy.idxmin()\n",
        "\n",
        "    print(f\"\\nBest Performing Subject: {most_accurate} ({subject_accuracy.max():.2f}%)\")\n",
        "    print(f\"Worst Performing Subject: {least_accurate} ({subject_accuracy.min():.2f}%)\")\n",
        "\n",
        "    # Common mistakes analysis\n",
        "    incorrect_df = df[df['correct'] == False]\n",
        "    if not incorrect_df.empty:\n",
        "        print(\"\\nSample Incorrect Predictions:\")\n",
        "        print(incorrect_df[['subject', 'question', 'correct_answer', 'predicted_answer']].sample(min(5, len(incorrect_df))))\n",
        "    else:\n",
        "        print(\"No incorrect predictions found!\")\n",
        "\n",
        "    return subject_accuracy\n"
      ],
      "metadata": {
        "id": "Tjdzx3WLGcTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_results(\"/content/mmlu_results_Qwen_Qwen2.5-1.5B-Instruct_ru.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "biWS0NXWGgH1",
        "outputId": "99ad33b9-c4e7-46f2-ccd3-188c741933d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 40.34%\n",
            "\n",
            "Accuracy by Subject:\n",
            "subject\n",
            "abstract_algebra            27.272727\n",
            "college_computer_science    36.363636\n",
            "college_mathematics         54.545455\n",
            "college_physics             36.363636\n",
            "computer_security           45.454545\n",
            "electrical_engineering      37.500000\n",
            "formal_logic                28.571429\n",
            "high_school_statistics      56.521739\n",
            "machine_learning            27.272727\n",
            "Name: correct, dtype: float64\n",
            "\n",
            "Best Performing Subject: high_school_statistics (56.52%)\n",
            "Worst Performing Subject: abstract_algebra (27.27%)\n",
            "\n",
            "Sample Incorrect Predictions:\n",
            "                     subject  \\\n",
            "43              formal_logic   \n",
            "14  college_computer_science   \n",
            "25       college_mathematics   \n",
            "73    high_school_statistics   \n",
            "46              formal_logic   \n",
            "\n",
            "                                             question correct_answer  \\\n",
            "43   Используйте косвенные таблицы истинности, что...              A   \n",
            "14  Пусть f(X) = если x = 1, то 0 еще [x * f(x - 1...              D   \n",
            "25  В ходе опроса 100 студентов математических спе...              A   \n",
            "73  В местной библиотеке есть сканер для обнаружен...              C   \n",
            "46   Используйте косвенные таблицы истинности, что...              D   \n",
            "\n",
            "   predicted_answer  \n",
            "43                B  \n",
            "14                A  \n",
            "25                C  \n",
            "73                A  \n",
            "46                B  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject\n",
              "abstract_algebra            27.272727\n",
              "college_computer_science    36.363636\n",
              "college_mathematics         54.545455\n",
              "college_physics             36.363636\n",
              "computer_security           45.454545\n",
              "electrical_engineering      37.500000\n",
              "formal_logic                28.571429\n",
              "high_school_statistics      56.521739\n",
              "machine_learning            27.272727\n",
              "Name: correct, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abstract_algebra</th>\n",
              "      <td>27.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_computer_science</th>\n",
              "      <td>36.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_mathematics</th>\n",
              "      <td>54.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>college_physics</th>\n",
              "      <td>36.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>computer_security</th>\n",
              "      <td>45.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>electrical_engineering</th>\n",
              "      <td>37.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>formal_logic</th>\n",
              "      <td>28.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_school_statistics</th>\n",
              "      <td>56.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>machine_learning</th>\n",
              "      <td>27.272727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qwen2.5 Russian Adaptation:"
      ],
      "metadata": {
        "id": "1nT77nWlw35g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Tokenization Training\n",
        "- Train a Russian-adapted tokenizer:\n",
        "  - **Options:** Full BPE/Unigram replacement, Vocabulary Extension, Optimized Tokenization\n",
        "  - **Best Practice:** Extend existing vocabulary to minimize performance degradation.\n"
      ],
      "metadata": {
        "id": "fPZkRP2MHPBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here im basically importing a cut down version of the complete new taiga dataset (98gb zip file)"
      ],
      "metadata": {
        "id": "Z0l6lw3NrCk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gathering training dataset:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "ajhkeaRo3ft2",
        "outputId": "375d6219-e438-49fb-ad81-cc6674b91681",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a2e9444257e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RussianNLP/tape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}